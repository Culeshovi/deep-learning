{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS(DCGAN)\n",
    "In the paper 'UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS' by Alec Radford, Luke Metz and Soumith Chintala several ideas were introduced for unsupervised learning by CNN. The DCGAN like GAN has both the Generator and Discriminator.A generator is a network that tries to create fake data identical to real data and discriminator tries to distinguish between fake and real data. To give an example let's assume Genrator creates counterfeit money and it's the job of the Discriminator to distinguish between real money and counterfeit money. Over time the Generator becomes better in creating counterfeit money which is identical to real money.\n",
    "\n",
    "The architecture guidelines from the DCGAN paper are:-\n",
    "- Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "- Use batchnorm in both the generator and the discriminator.\n",
    "- Remove fully connected hidden layers for deeper architectures.\n",
    "- Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "- Use LeakyReLU activation in the discriminator for all layers.\n",
    "\n",
    "<img src='images/dcgan2.png'>\n",
    "                                               <center><h2>DCGAN ARCHITECTURE</h2></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf   #importing Modules\n",
    "import numpy as np\n",
    "import os,imageio,itertools,time,pickle\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data/\", one_hot=True,reshape=[]) #one hot true does one hot encoding\n",
    "tf.reset_default_graph()\n",
    "batch_size=50\n",
    "lr=0.0002\n",
    "epoch=100\n",
    "display_epoch = 1\n",
    "logs_path = 'dcgan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x,phase_train=True):\n",
    "    with tf.name_scope('bn'):\n",
    "        normed=tf.cond(phase_train,lambda:tf.contrib.layers.batch_norm(x,epsilon=1e-5),lambda:tf.contrib.layers.batch_norm(x,epsilon=1e-5,is_training=False))\n",
    "        return normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "It takes input size of 64x64 image and after several strided convolution layers tries to predict whether the image is fake or real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x,phase_train,reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        l1=tf.layers.conv2d(x, 128, [4, 4], strides=(2, 2), padding='same')\n",
    "        l1=tf.nn.leaky_relu(l1)\n",
    "        l2=tf.layers.conv2d(l1, 256, [4, 4], strides=(2, 2), padding='same')\n",
    "        l2=batch_norm(l2,phase_train)\n",
    "        l2=tf.nn.leaky_relu(l2)\n",
    "        l3=tf.layers.conv2d(l2, 512, [4, 4], strides=(2, 2), padding='same')\n",
    "        l3=batch_norm(l3,phase_train)\n",
    "        l3=tf.nn.leaky_relu(l3)\n",
    "        l4=tf.layers.conv2d(l3, 1024, [4, 4], strides=(2, 2), padding='same')\n",
    "        l4=batch_norm(l4,phase_train)\n",
    "        l4=tf.nn.leaky_relu(l4)\n",
    "        l5=tf.layers.conv2d(l4, 1, [4, 4], strides=(1, 1), padding='valid')\n",
    "        o=tf.nn.sigmoid(l5)\n",
    "        return o,l5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "It starts from a completely random distribution and learns to fool the discriminator after going through several deconvolution operations along with upsampling. At the end it outputs a 64x64 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z_dim,phase_train,reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        l0=tf.layers.conv2d_transpose(z_dim, 1024, [4, 4], strides=(1, 1), padding='valid')\n",
    "        l0=batch_norm(l0,phase_train)\n",
    "        l0=tf.nn.relu(l0)\n",
    "        l1=tf.layers.conv2d_transpose(l0, 512, [4, 4], strides=(2, 2), padding='same')\n",
    "        l1=batch_norm(l1,phase_train)\n",
    "        l1=tf.nn.relu(l1)\n",
    "        l2=tf.layers.conv2d_transpose(l1, 256, [4, 4], strides=(2, 2), padding='same')\n",
    "        l2=batch_norm(l2,phase_train)\n",
    "        l2=tf.nn.relu(l2)\n",
    "        l3=tf.layers.conv2d_transpose(l2, 128, [4, 4], strides=(2, 2), padding='same')\n",
    "        l3=batch_norm(l3,phase_train)\n",
    "        l3=tf.nn.relu(l3)\n",
    "        l4=tf.layers.conv2d_transpose(l3, 1, [4, 4], strides=(2, 2), padding='same')\n",
    "        l5=tf.nn.tanh(l4)\n",
    "        return l5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "The following few lines of code help in visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = 'MNIST_DCGAN_results/'\n",
    "model = 'MNIST_DCGAN_'\n",
    "if not os.path.isdir(root):\n",
    "    os.mkdir(root)\n",
    "if not os.path.isdir(root + 'Fixed_results'):\n",
    "    os.mkdir(root + 'Fixed_results')\n",
    "\n",
    "fixed_z_ = np.random.normal(0, 1, (batch_size, 1, 1, 100))\n",
    "def show_result(num_epoch, show = False, save = False, path = 'result.png'):\n",
    "    test_images = sess.run(g_i, {z_dim: fixed_z_, phase_train: False})\n",
    "\n",
    "    size_figure_grid = 5\n",
    "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "        ax[i, j].get_xaxis().set_visible(False)\n",
    "        ax[i, j].get_yaxis().set_visible(False)\n",
    "\n",
    "    for k in range(size_figure_grid*size_figure_grid):\n",
    "        i = k // size_figure_grid\n",
    "        j = k % size_figure_grid\n",
    "        ax[i, j].cla()\n",
    "        ax[i, j].imshow(np.reshape(test_images[k], (64, 64)), cmap='gray')\n",
    "\n",
    "    label = 'Epoch {0}'.format(num_epoch)\n",
    "    fig.text(0.5, 0.04, label, ha='center')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('inputs') as inputs: #Inputs of the Network\n",
    "        x = tf.placeholder(tf.float32, shape=(None,64,64,1), name='x')\n",
    "        z_dim = tf.placeholder(tf.float32, shape=(None,1,1,100), name='z_dim')\n",
    "        phase_train = tf.placeholder(tf.bool, name='phase_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Generator'): \n",
    "    g = generator(z_dim,phase_train,reuse=False)# Takes a random distribution(z_dim) as input and returns a 64x64 image.\n",
    "\n",
    "with tf.name_scope('Generator_I'): #Visualization Operation, Uses the previous trained variables (reuse=True).   \n",
    "    g_i= generator(z_dim,phase_train,reuse=True)\n",
    "    \n",
    "gs=tf.summary.image('Generator',g, max_outputs=10) #Tensoroard Visualization Op\n",
    "\n",
    "with tf.name_scope('Discriminator_T'): #Real Data as Input\n",
    "    d_t ,d_tlog= discriminator(x,phase_train,reuse=False)\n",
    "with tf.name_scope('Discriminator_F'): #Fake Data as Input\n",
    "    d_f ,d_flog= discriminator(g,phase_train,reuse=True)\n",
    "#Tensorboard_Op\n",
    "d_fs=tf.summary.histogram(\"Discriminator_FACT\",d_f)\n",
    "d_ts=tf.summary.histogram(\"Discriminator_TACT\",d_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Discriminator_Loss_Fake'): #The Discriminator will set Generator's Fake Data as 0\n",
    "    dfcost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_flog, labels=tf.zeros_like(d_f)))\n",
    "    dfcosts=tf.summary.scalar(\"Discriminator_Loss_Fake\",dfcost)\n",
    "\n",
    "with tf.name_scope('Discriminator_Loss_Real'): #The Discriminator will set Real Data input as 1, 0.9 is multiplied for label smoothning.\n",
    "    dtcost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_tlog, labels= tf.ones_like(d_t)*0.9))\n",
    "    dtcosts=tf.summary.scalar(\"Discriminator_Loss_Real\",dtcost)\n",
    "\n",
    "with tf.name_scope('Discriminator_Loss'):#The Two losses are added\n",
    "    dcost=dtcost+dfcost\n",
    "    dcosts=tf.summary.scalar('Discriminator_Loss',dcost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Generator_Loss'): #The Generator will try to fool the Discriminator \n",
    "    gcost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_flog, labels=tf.ones_like(d_f)))\n",
    "    gcosts=tf.summary.scalar('Generator_Loss',gcost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_vars = tf.trainable_variables() #Making list of Trainable Variables\n",
    "D_vars = [var for var in T_vars if var.name.startswith('discriminator')]\n",
    "G_vars = [var for var in T_vars if var.name.startswith('generator')]\n",
    "\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): #Using Adam Optimizer\n",
    "    D_optim = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(dcost, var_list=D_vars)\n",
    "    G_optim = tf.train.AdamOptimizer(lr, beta1=0.5).minimize(gcost, var_list=G_vars)\n",
    "#Tensorboard Operation\n",
    "d_summary=tf.summary.merge([dcosts,])\n",
    "g_summary=tf.summary.merge([gcosts,gs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_config = tf.ConfigProto()\n",
    "run_config.gpu_options.allow_growth=True\n",
    "with tf.Session(config=run_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(logs_path)  #WritesTheGraphForTensorboard\n",
    "    summary_writer.add_graph(graph=sess.graph)        \n",
    "    gstep=1\n",
    "    train_set=tf.image.resize_images(mnist.train.images, [64, 64]).eval(session=sess)\n",
    "    train_set=(train_set-0.5)/0.5\n",
    "    for i in range(epoch):\n",
    "            g_loss = []\n",
    "            d_loss = []            #calculate loss\n",
    "            for j in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x = train_set[j*batch_size:(j+1)*batch_size]\n",
    "                #epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                #epoch_x=(epoch_x-0.5)/0.5\n",
    "                #epoch_x=np.resize(np.reshape(epoch_x,[-1,28,28,1]),[batch_size,64,64,1])\n",
    "                z=np.random.normal(0, 1, (batch_size, 1, 1, 100))\n",
    "                _,d_l,summary1=sess.run([D_optim,dcost,d_summary],feed_dict={x:epoch_x,z_dim:z,phase_train:True})\n",
    "                d_loss.append([d_l])\n",
    "                summary_writer.add_summary(summary1,gstep)\n",
    "                z=np.random.normal(0, 1, (batch_size, 1, 1, 100))\n",
    "                _,g_l,summary2 = sess.run([G_optim,gcost,g_summary],feed_dict={x:epoch_x,z_dim:z,phase_train:True})\n",
    "                g_loss.append([g_l])\n",
    "                summary_writer.add_summary(summary2,gstep) #Writes Summary\n",
    "                gstep+=1\n",
    "            print (\"epoch done\")\n",
    "            fixed_p = root + 'Fixed_results/' + model + str(i + 1) + '.png'\n",
    "            show_result((i + 1), save=True, path=fixed_p)\n",
    "            print('Epoch', i, 'completed out of',epoch,'generator loss:',np.mean(g_loss),'discriminator loss:',np.mean(d_loss))\n",
    "\n",
    "images = [] #Gif Creation\n",
    "for e in range(epoch):\n",
    "    img_name = root + 'Fixed_results/' + model + str(e + 1) + '.png'\n",
    "    images.append(imageio.imread(img_name))\n",
    "imageio.mimsave(root + model + 'generation_animation.gif', images, fps=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generated Samples\n",
    "<img src='images\\MNIST_DCGAN_1.png'> <img src='images\\MNIST_DCGAN_100.png'> <img src='images\\MNIST_DCGAN2generation_animation.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the command line:\n",
      "--> tensorboard --logdir=dcgan \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=dcgan \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Graph Of The Network\n",
    "<img src='images\\dcgan.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator And Generator Losses\n",
    "<img src='images\\Capture.PNG'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
